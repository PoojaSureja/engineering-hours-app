{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a74288de-dc51-48aa-82ac-69c7ad1fd05a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Repos/psureja@toromontcat.com/imacs_engineering_hours/notebooks/utility/utility_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e54931b2-91f1-4b18-9764-81a4fa9aa115",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import unittest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4165fd6-f198-4776-8b14-040a17302913",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "table_names=[\"lh_imacs.EA_Project_ActualHours\",\"lh_imacs.EA_Project_BudgetEACHours\"]\n",
    "dataframe_names = [\"df_project_actualHours\",\"df_Project_BudgetEACHours\"]\n",
    "\n",
    "\n",
    "\n",
    "class Test_load_dataset(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUpClass(self):\n",
    "        self.a_2_2 = load_dataset(table_names, dataframe_names)\n",
    "\n",
    "    def test_load_dataset(self):\n",
    "    #   self.assertIn('a', globals(), \"'a' not in globals()\")\n",
    "    #   self.assertIn('b', globals(), \"'b' not in globals()\")\n",
    "    #   self.assertIn('c', globals(), \"'c' not in globals()\")\n",
    "    #   self.assertIn('d', globals(), \"'d' not in globals()\")\n",
    "    #   self.assertEqual(globals()['a'], 'c', 'globals()[a] is not assigned to c' )\n",
    "    #   self.assertEqual(globals()['d'], 'c', 'globals()[a] is not assigned to c' )\n",
    "        pass\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_load_dataset)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0536166b-3c75-4072-ae14-3b122dd395ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_trim_and_lower(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {'TeSt':['AaRdVaRk', 'APPLE', 'alligator'], \n",
    "             '   test_2  ':['delta  ','   disaster', '   dilapidated   ']})\n",
    "        self.df_sp = trim_and_lower(spark.createDataFrame(self.df_pd), ['TeSt', '   test_2  '])\n",
    "\n",
    "    def test_trim_post(self):\n",
    "        self.assertEqual(self.df_sp.collect()[0][1], 'delta')\n",
    "\n",
    "    def test_trim_pre(self):\n",
    "        self.assertEqual(self.df_sp.collect()[1][1], 'disaster')\n",
    "\n",
    "    def test_trim_both(self):\n",
    "        self.assertEqual(self.df_sp.collect()[2][1], 'dilapidated')\n",
    "\n",
    "    def test_lower_mixed(self):\n",
    "        self.assertEqual(self.df_sp.collect()[0][0], 'aardvark')\n",
    "\n",
    "    def test_lower_all(self):\n",
    "        self.assertEqual(self.df_sp.collect()[1][0], 'apple')\n",
    "\n",
    "    def test_lower_none(self):\n",
    "        self.assertEqual(self.df_sp.collect()[2][0], 'alligator')\n",
    "    \n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_trim_and_lower)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "607f3932-c5b9-469d-8ff6-382c38ecea8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_format_actual_hours(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'StockNo': ['a', 'b', 'c'],\n",
    "                'TypeCode': ['ME', 'EE', 'PM'],\n",
    "                'Hours': [8.0, 3.5, 155.7],\n",
    "                'ServiceSegment': ['aa', 'bb', 'cc'],\n",
    "                'ServiceDate': ['07-12-2025', '01-03-2023', '12-04-2024'], # need to check actual date format and retest when data is connected\n",
    "                'Test1': ['ab', 'ba', 'ac'],\n",
    "                'Test2': [123, 45, 82]\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "    def test_kept_columns(self):\n",
    "        for col_ in ['StockNo', 'TypeCode', 'Hours','ServiceSegment','ServiceMonthYear']:\n",
    "            self.assertIn(col_, format_actual_hours(self.df_sp).columns)\n",
    "\n",
    "    def test_removed_columns(self):\n",
    "        for col_ in ['Test1', 'Test2']:\n",
    "            self.assertNotIn(col_, format_actual_hours(self.df_sp).columns)\n",
    "\n",
    "    def test_month_year(self):\n",
    "        self.assertEqual(format_actual_hours(self.df_sp).collect()[0][4], '2025-12')\n",
    "        self.assertEqual(format_actual_hours(self.df_sp).collect()[1][4], '2023-03')\n",
    "        self.assertEqual(format_actual_hours(self.df_sp).collect()[2][4], '2024-04')\n",
    "\n",
    "    \n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_format_actual_hours)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "db0c7b17-5a23-4df7-82e1-a560f80ac6e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_format_EAC_hours(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'StockNo': ['a', 'b', 'c'],\n",
    "                'ProjectNo': [1, 2, 3],\n",
    "                'SellPriceCAD': [8.0, 3.5, 155.7],\n",
    "                'Model': ['aa', 'bb', 'cc'],\n",
    "                'StockType': ['gh', 'ht', 'tg'], \n",
    "                'IndustryCode': ['rj', 'j', 'ij'], \n",
    "                'Test1': ['ab', 'ba', 'ac'],\n",
    "                'Test2': [123, 45, 82]\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "    def test_kept_columns(self):\n",
    "        for col_ in ['StockNo', 'ProjectNo','SellPriceCAD','IndustryCode','Model','Stocktype']:\n",
    "            self.assertIn(col_, format_EAC_hours(self.df_sp).columns)\n",
    "\n",
    "    def test_removed_columns(self):\n",
    "        for col_ in ['Test1', 'Test2']:\n",
    "            self.assertNotIn(col_, format_EAC_hours(self.df_sp).columns)\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_format_EAC_hours)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "43327bee-9e26-47ce-873d-ec79642e4928",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_join_EAC_to_actual(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd_eac = pd.DataFrame(\n",
    "            {\n",
    "                'StockNo': ['a', 'b', 'd'],\n",
    "                'ProjectNo': [1, 2, 3],\n",
    "                'SellPriceCAD': [8.0, 3.5, 155.7],\n",
    "                'Model': ['aa', 'bb', 'cc'],\n",
    "            }\n",
    "        )\n",
    "        self.df_sp_eac = spark.createDataFrame(self.df_pd_eac)\n",
    "        self.df_pd_act = pd.DataFrame(\n",
    "            {\n",
    "                'StockNo': ['a', 'b', 'c'],\n",
    "                'TypeCode': ['ME', 'EE', 'PM'],\n",
    "                'Hours': [8.0, 3.5, 155.7],\n",
    "            }\n",
    "        )\n",
    "        self.df_sp_act = spark.createDataFrame(self.df_pd_act)\n",
    "\n",
    "    def test_joined_project_no(self):\n",
    "        self.assertEqual(join_EAC_to_actual(self.df_sp_act, self.df_sp_eac).collect()[0][3], 1)\n",
    "        self.assertEqual(join_EAC_to_actual(self.df_sp_act, self.df_sp_eac).collect()[1][3], 2)\n",
    "\n",
    "    def test_joined_columns(self):\n",
    "        for col_ in ['StockNo', 'ProjectNo', 'SellPriceCAD', 'Model', 'TypeCode', 'Hours']:\n",
    "            self.assertIn(col_, join_EAC_to_actual(self.df_sp_act, self.df_sp_eac).columns)\n",
    "\n",
    "    def test_dropped_rows(self):\n",
    "        self.assertEqual(join_EAC_to_actual(self.df_sp_act, self.df_sp_eac).count(), 2)\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_join_EAC_to_actual)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2972ffed-fcbe-47f1-bc9e-a0faef844d0f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_clean_joined(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'StockNo': ['a', 'b', 'd'],\n",
    "                'ProjectNo': [1, 2, None],\n",
    "                'Hours': [8.0, -3.5, 155.7]\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "\n",
    "    def test_dropped_rows(self):\n",
    "        self.assertEqual(clean_joined(self.df_sp).count(), 1)\n",
    "        self.assertEqual(clean_joined(self.df_sp).filter(col('hours')<0).count(), 0)\n",
    "        self.assertEqual(clean_joined(self.df_sp).filter(col('hours').isNull()).count(), 0)\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_clean_joined)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "202e1a31-aaa0-4dc4-a8c7-d03dbc3fe629",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_add_recency_ind(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'StockNo': ['a', 'b', 'd'],\n",
    "                'ProjectNo': [1, 2, 3],\n",
    "                'SellPriceCAD': [8.0, 3.5, 155.7],\n",
    "                'ServiceMonthYear': ['2019-12', '2020-01', '2021-01']\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "    def test_joined_columns(self):\n",
    "        for col_ in ['StockNo', 'ProjectNo', 'SellPriceCAD', 'ServiceMonthYear', 'recency_ind']:\n",
    "            self.assertIn(col_, add_recency_ind(self.df_sp).columns)\n",
    "\n",
    "    def test_joined_project_no(self):\n",
    "        self.assertEqual(add_recency_ind(self.df_sp).collect()[0][4], 0)\n",
    "        self.assertEqual(add_recency_ind(self.df_sp).collect()[1][4], 1)\n",
    "        self.assertEqual(add_recency_ind(self.df_sp).collect()[2][4], 1)\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_add_recency_ind)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa450633-f8f0-4c6e-ad59-c5b49294c734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_compress_to_project_level(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'ProjectNo': [1, 2, 3, 1, 2],\n",
    "                'StockNo': ['a', 'b', 'c', 'd', 'e'],\n",
    "                'SellPriceCAD': [8.0, 3.5, 155.7, 7.0, -2],\n",
    "                'Model': ['a', 'b', 'c', 'a', 'c'],\n",
    "                'recency_ind': [1, 1, 1, 0, 1],\n",
    "                'Hours': [5, 10, 15, 20, 25],\n",
    "                'IndustryCode': ['a', 'b', 'c', 'b', 'a']\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "    def test_grouping(self):\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).count(), 3)\n",
    "\n",
    "    def test_stock_count(self):\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[0][1], 2)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[1][1], 2)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[2][1], 1)\n",
    "\n",
    "    def test_distinct_model_count(self):\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[0][2], 1)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[1][2], 2)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[2][2], 1)\n",
    "\n",
    "    def test_recency_ind(self):\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[0][3], 0)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[1][3], 1)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[2][3], 1)\n",
    "\n",
    "    def test_hour_sum(self):\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[0][4], 25)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[1][4], 35)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[2][4], 15)\n",
    "\n",
    "    def test_sell_price_sum(self):\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[0][5], 15)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[1][5], 1.5)\n",
    "        self.assertEqual(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[2][5], 155.7)\n",
    "\n",
    "    def test_industry_code(self):\n",
    "        # we don't actually care which industry code is chosen, so only checking inclusion instead of specific equality\n",
    "        self.assertIn(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[0][6], {'a', 'b'})\n",
    "        self.assertIn(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[1][6], {'a', 'b'})\n",
    "        self.assertIn(compress_to_project_level(self.df_sp).sort('ProjectNo').collect()[2][6], {'c'})\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_compress_to_project_level)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "898e27c7-beb9-425f-8093-a60e1c32f589",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_filter_outliers(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'ProjectNo': [1, 2, 3, 4],\n",
    "                'stock_count': [500, 501, 500, 500],\n",
    "                'total_sell_price': [100000000, 100000000, 100000001, 100000000],\n",
    "                'hours': [1500, 1500, 1500, 1501],\n",
    "                'ServiceMonthYear': ['a', 'b', 'c', 'd']\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "    def test_removed_rows(self):\n",
    "        self.assertEqual(filter_outliers(self.df_sp).count(), 1)\n",
    "\n",
    "    def test_removed_values(self):\n",
    "        self.assertEqual(filter_outliers(self.df_sp).collect()[0][1], 500)\n",
    "        self.assertEqual(filter_outliers(self.df_sp).collect()[0][2], 100000000)\n",
    "        self.assertEqual(filter_outliers(self.df_sp).collect()[0][3], 1500)\n",
    "\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_filter_outliers)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a3ba03b-d9b7-463c-81b0-ce0e059777e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "class Test_bc_transform(unittest.TestCase):\n",
    "\n",
    "    @classmethod\n",
    "    def setUp(self):\n",
    "        self.df_pd = pd.DataFrame(\n",
    "            {\n",
    "                'ProjectNo': [1, 2, 3, 4],\n",
    "                'stock_count': [500, 2501, 5070, 500],\n",
    "                'hours': [15, 150, 1500, 15000],\n",
    "            }\n",
    "        )\n",
    "        self.df_sp = spark.createDataFrame(self.df_pd)\n",
    "\n",
    "    def test_feature_invariance(self):\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[0][0], 1)\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[1][0], 2)\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[2][0], 3)\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[3][0], 4)\n",
    "\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[0][1], 500)\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[1][1], 2501)\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[2][1], 5070)\n",
    "        self.assertEqual(bc_transform(self.df_sp)[0].collect()[3][1], 500)\n",
    "\n",
    "    def test_target_change(self):\n",
    "        self.assertNotEqual(bc_transform(self.df_sp)[0].collect()[0][2], 15)\n",
    "        self.assertNotEqual(bc_transform(self.df_sp)[0].collect()[1][2], 150)\n",
    "        self.assertNotEqual(bc_transform(self.df_sp)[0].collect()[2][2], 1500)\n",
    "        self.assertNotEqual(bc_transform(self.df_sp)[0].collect()[3][2], 15000)\n",
    "\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromTestCase(Test_bc_transform)\n",
    "runner = unittest.TextTestRunner(verbosity=100)\n",
    "results = runner.run(suite)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "utility_functions_test",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
